{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": [
     "header",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# The Institute for the Design of Advanced Energy Systems Integrated Platform\n",
    "# Framework (IDAES IP) was produced under the DOE Institute for the\n",
    "# Design of Advanced Energy Systems (IDAES), and is copyright (c) 2018-2022\n",
    "# by the software owners: The Regents of the University of California, through\n",
    "# Lawrence Berkeley National Laboratory,  National Technology & Engineering\n",
    "# Solutions of Sandia, LLC, Carnegie Mellon University, West Virginia University\n",
    "# Research Corporation, et al.  All rights reserved.\n",
    "#\n",
    "# Please see the files COPYRIGHT.md and LICENSE.md for full copyright and\n",
    "# license information.\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameter Estimation for a Single Unit - Economizer\n",
    "\n",
    "This notebook demonstrates parameter estimation continuing from the data reconciliation results in ```econ_recon.ipynb``` or ```boiler_recon.ipynb```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data\n",
    "\n",
    "The data used here is produced by the data reconciliation step.  The data tags are mostly systematically generated from stream names to minimize effort in mapping data to the model.  The same model is used for parameter reconciliation and data reconciliation, so the stream names are consistent and any data mapping can be reused.  The bin information columns where included in the data reconciliation output, so there is no need to bin the data again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import idaes.core.dmf.model_data as da\n",
    "from idaes.logger import getLogger\n",
    "import logging\n",
    "\n",
    "getLogger(\"idaes.core\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either economizer only or full boiler data reconciliation results can be used here.  You can select below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_data = \"econ_recon.csv\"\n",
    "\n",
    "# Uncomment the next line to use boiler recon data.\n",
    "# recon_data = \"boiler_recon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is already tagged to match the model and in the correct units, we directly read the data\n",
    "# into a Pandas data frame, and there is no need to use the data processing functions that were used in the\n",
    "# data reconciliation notebook (although they could be used here).\n",
    "df = pd.read_csv(recon_data)\n",
    "\n",
    "# Calculate the standard deviations of the binned data\n",
    "bin_stdev = da.bin_stdev(df, bin_no=\"bin_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to set the model data.  In this case, we take the data reconciliation results for model input to be correct and set those in the model.  Another approach would be to also estimate model inputs given that there is some uncertainty in their measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'set_data' function below takes data from the DataFrame and updates the model data parameters.\n",
    "def set_data(m, df, data_tags, index=None):\n",
    "    if index is None:\n",
    "        index = df.index[0]\n",
    "    dft = df.transpose()[index]\n",
    "    m.bin_no = dft[\"bin_no\"]\n",
    "    m.data.store_values(dft[data_tags])\n",
    "    m.data_stdev.store_values(bin_stdev[m.bin_no][data_tags])\n",
    "    # Set the inlet streams from the data.\n",
    "    input_tags = [\n",
    "        \"BFW_h\",\n",
    "        \"BFW_P\",\n",
    "        \"BFW_F\",\n",
    "        \"FG_2_ECON_T\",\n",
    "        \"FG_2_ECON_P\",\n",
    "        \"FG_2_ECON_F[O2]\",\n",
    "        \"FG_2_ECON_F[NO]\",\n",
    "        \"FG_2_ECON_F[N2]\",\n",
    "        \"FG_2_ECON_F[SO2]\",\n",
    "        \"FG_2_ECON_F[CO2]\",\n",
    "        \"FG_2_ECON_F[H2O]\",\n",
    "    ]\n",
    "    for t in input_tags:\n",
    "        m.data_tags[t].expression.value = dft[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Create Model Generator Function\n",
    "\n",
    "We use the Parmest tool from Pyomo to do the parameter estimation here, which requires a function to generate a model for each case.  The cases are put together by Parmest to set up a parameter estimation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "import os\n",
    "import pyomo.environ as pyo\n",
    "from idaes.core.util import model_serializer as ms\n",
    "from idaes.core import FlowsheetBlock\n",
    "from idaes.models_extra.power_generation.properties.flue_gas_ideal import (\n",
    "    FlueGasParameterBlock,\n",
    ")\n",
    "from idaes.models_extra.power_generation.unit_models.boiler_heat_exchanger import (\n",
    "    BoilerHeatExchanger,\n",
    "    TubeArrangement,\n",
    "    HeatExchangerFlowPattern,\n",
    ")\n",
    "from idaes.models.properties import iapws95\n",
    "import idaes.core.util.tables as ta\n",
    "from idaes.core.util.tags import ModelTagGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a function to get an instance of the economizer model.\n",
    "\n",
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "\n",
    "\n",
    "def get_model(data):\n",
    "    m = pyo.ConcreteModel()\n",
    "    m.fs = FlowsheetBlock(dynamic=False, time_units=pyo.units.s)\n",
    "    m.fs.prop_water = iapws95.Iapws95ParameterBlock()\n",
    "    m.fs.prop_fluegas = FlueGasParameterBlock()\n",
    "\n",
    "    m.fs.econ = BoilerHeatExchanger(\n",
    "        cold_side={\"property_package\": m.fs.prop_water, \"has_pressure_change\": True},\n",
    "        hot_side={\"property_package\": m.fs.prop_fluegas, \"has_pressure_change\": True},\n",
    "        has_holdup=False,\n",
    "        flow_pattern=HeatExchangerFlowPattern.countercurrent,\n",
    "        tube_arrangement=TubeArrangement.inLine,\n",
    "        cold_side_water_phase=\"Liq\",\n",
    "        has_radiation=False,\n",
    "    )\n",
    "    # Set inputs and initialize.  Since the initialization is repeated each time a\n",
    "    # model is created, we'll save the results and reload them.\n",
    "    if os.path.isfile(\"econ_init.json.gz\"):\n",
    "        ms.from_json(m, fname=\"econ_init.json.gz\")\n",
    "    else:\n",
    "        h = pyo.value(iapws95.htpx(563.706 * pyo.units.K, 2.5449e7 * pyo.units.Pa))\n",
    "        m.fs.econ.cold_side_inlet.flow_mol[0].fix(24678.26)  # mol/s\n",
    "        m.fs.econ.cold_side_inlet.enth_mol[0].fix(h)  # J/mol\n",
    "        m.fs.econ.cold_side_inlet.pressure[0].fix(2.5449e7)  # Pa\n",
    "\n",
    "        # Set the flue gas flow and composition\n",
    "        fg_rate = 28.3876e3  # mol/s equivalent of ~1930.08 klb/hr\n",
    "        fg_comp = {  # mol fraction of flue gas components\n",
    "            \"H2O\": 8.69 / 100,\n",
    "            \"CO2\": 14.49 / 100,\n",
    "            \"O2\": 2.47 / 100,\n",
    "            \"NO\": 0.0006,\n",
    "            \"SO2\": 0.002,\n",
    "        }\n",
    "        # The rest is N2\n",
    "        fg_comp[\"N2\"] = 1 - sum(fg_comp[i] for i in fg_comp)\n",
    "\n",
    "        # Set economizer inlets\n",
    "        for c in fg_comp:\n",
    "            m.fs.econ.hot_side.properties_in[0].flow_mol_comp[c].fix(\n",
    "                fg_rate * fg_comp[c]\n",
    "            )\n",
    "        m.fs.econ.hot_side_inlet.temperature[0].fix(682.335)  # K\n",
    "        m.fs.econ.hot_side_inlet.pressure[0].fix(100145)  # Pa\n",
    "\n",
    "        # Set economizer design variables and parameters\n",
    "        ITM = 0.0254  # inch to meter conversion\n",
    "        # Based on NETL Baseline Report Rev4\n",
    "        m.fs.econ.tube_thickness.fix(0.188 * ITM)  # tube thickness\n",
    "        m.fs.econ.tube_di.fix((2.0 - 2.0 * 0.188) * ITM)  # calc inner diameter\n",
    "        m.fs.econ.pitch_x.fix(3.5 * ITM)\n",
    "        m.fs.econ.pitch_y.fix(5.03 * ITM)\n",
    "        m.fs.econ.tube_length.fix(53.41 * 12 * ITM)  # use tube length (53.41 ft)\n",
    "        m.fs.econ.tube_nrow.fix(36 * 2.5)  # use to match baseline performance\n",
    "        m.fs.econ.tube_ncol.fix(130)  # 130 from thermoflow\n",
    "        m.fs.econ.nrow_inlet.fix(2)\n",
    "        m.fs.econ.delta_elevation.fix(50)\n",
    "        m.fs.econ.tube_r_fouling = 0.000176\n",
    "        m.fs.econ.shell_r_fouling = 0.00088\n",
    "        m.fs.econ.fcorrection_htc.fix(1.5)\n",
    "        m.fs.econ.fcorrection_dp_tube.fix(1.0)\n",
    "        m.fs.econ.fcorrection_dp_shell.fix(1.0)\n",
    "        m.fs.econ.initialize(\n",
    "            state_args_1={\n",
    "                \"flow_mol\": m.fs.econ.cold_side_inlet.flow_mol[0].value,\n",
    "                \"pressure\": m.fs.econ.cold_side_inlet.pressure[0].value,\n",
    "                \"enth_mol\": m.fs.econ.cold_side_inlet.enth_mol[0].value,\n",
    "            },\n",
    "            state_args_2={\n",
    "                \"flow_component\": {\n",
    "                    \"H2O\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"H2O\"].value,\n",
    "                    \"CO2\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"CO2\"].value,\n",
    "                    \"N2\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"N2\"].value,\n",
    "                    \"O2\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"O2\"].value,\n",
    "                    \"NO\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"NO\"].value,\n",
    "                    \"SO2\": m.fs.econ.hot_side_inlet.flow_mol_comp[0, \"SO2\"].value,\n",
    "                },\n",
    "                \"temperature\": m.fs.econ.hot_side_inlet.temperature[0].value,\n",
    "                \"pressure\": m.fs.econ.hot_side_inlet.pressure[0].value,\n",
    "            },\n",
    "        )\n",
    "        ms.to_json(m, fname=\"econ_init.json.gz\")\n",
    "\n",
    "    # Add tags and data parameters\n",
    "    stream_dict = ta.arcs_to_stream_dict(\n",
    "        m,\n",
    "        additional={\n",
    "            \"BFW\": m.fs.econ.cold_side_inlet,\n",
    "            \"ECON_OUT\": m.fs.econ.cold_side_outlet,\n",
    "            \"FG_2_ECON\": m.fs.econ.hot_side_inlet,\n",
    "            \"FG_2_AIRPH\": m.fs.econ.hot_side_outlet,\n",
    "        },\n",
    "        sort=True,\n",
    "    )\n",
    "    state_dict = ta.stream_states_dict(stream_dict, time_point=0)\n",
    "    m.data_tags = ModelTagGroup()\n",
    "\n",
    "    prop_dict = {\n",
    "        \"flow_mass\": \"_Fm\",\n",
    "        \"flow_mol\": \"_F\",\n",
    "        \"enth_mol\": \"_h\",\n",
    "        \"temperature\": \"_T\",\n",
    "        \"pressure\": \"_P\",\n",
    "    }\n",
    "    comp_list = [\"O2\", \"NO\", \"N2\", \"SO2\", \"CO2\", \"H2O\"]\n",
    "\n",
    "    for state, block in state_dict.items():\n",
    "        for prop, suffix in prop_dict.items():\n",
    "            comp = getattr(block, prop)\n",
    "            m.data_tags.add(expr=comp, name=state + suffix, format_string=\"{:.3f}\")\n",
    "        # Add tags for molar flow rates of each component\n",
    "        for j in comp_list:\n",
    "            # Not all components appear in all streams\n",
    "            try:\n",
    "                comp = block.flow_mol_comp[j]\n",
    "                m.data_tags.add(\n",
    "                    expr=comp, name=f\"{state}_F[{j}]\", format_string=\"{:.3f}\"\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    m.data_tags.add(expr=m.fs.econ.heat_duty[0], name=\"ECON_Q\", format_string=\"{:.3f}\")\n",
    "\n",
    "    m.data = pyo.Param(\n",
    "        m.data_tags, mutable=True, doc=\"Process data for a specific point in time.\"\n",
    "    )\n",
    "    m.data_stdev = pyo.Param(\n",
    "        m.data_tags, mutable=True, doc=\"Process data standard deviation.\"\n",
    "    )\n",
    "\n",
    "    @m.Expression(m.data_tags)\n",
    "    def err(m, i):\n",
    "        return (m.data[i] - m.data_tags[i].expression) / m.data_stdev[i]\n",
    "\n",
    "    # Set the data\n",
    "    set_data(m, data, data_tags=pd.Series(m.data_tags.keys()))\n",
    "    solver.solve(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the get model function\n",
    "solver = pyo.SolverFactory(\"ipopt\")\n",
    "print(df.index)\n",
    "m = get_model(df)\n",
    "\n",
    "# Solve the model at the first data point\n",
    "res = solver.solve(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model result at the first data point\n",
    "from idaes.core.util.tags import svg_tag  # utility to place numbers/text in an SVG\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "with open(\"econ.svg\", \"r\") as f:\n",
    "    s = svg_tag(svg=f, tag_group=m.data_tags, outfile=\"econ_init.svg\")\n",
    "display(SVG(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "testing"
    ]
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "testing"
    ]
   },
   "outputs": [],
   "source": [
    "assert pyo.value(m.data_tags[\"ECON_Q\"].expression) == pytest.approx(1.3410e8, rel=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up Parameter Estimation\n",
    "\n",
    "Here we use the Parmest tool to solve the parameter estimation problem.  The theta_names list is a list of parameters to estimate.  The theta names strings are the location of the parameters in the model.  A function ```sse()``` is also defined that creates the objective function for each model instance.  The objective from the individual cases is summed to produce the overall parameter estimation objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters to estimate\n",
    "theta_names = [\n",
    "    \"fs.econ.fcorrection_htc\",\n",
    "    \"fs.econ.fcorrection_dp_tube\",\n",
    "    \"fs.econ.fcorrection_dp_shell\",\n",
    "]\n",
    "\n",
    "# Tags to include in the objective\n",
    "objective_tags = {\n",
    "    \"ECON_OUT_P\",\n",
    "    \"ECON_OUT_T\",\n",
    "    \"FG_2_AIRPH_T\",\n",
    "    \"FG_2_AIRPH_P\",\n",
    "}\n",
    "\n",
    "# Return expressions for the objective\n",
    "def sse(model, data):\n",
    "    return sum((model.err[i]) ** 2 for i in objective_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Parmest and record the results.  Here we group the data by bin.  Each parameter in theta_names will be estimated based on all the points in a bin.  This will allow us to examine whether the parameters have a dependence on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.contrib.parmest.parmest as parmest\n",
    "import numpy as np\n",
    "\n",
    "parmest_results = {}\n",
    "# run parmest tool for each power bin\n",
    "for i, group in df.groupby(\"bin_no\"):\n",
    "    pest = parmest.Estimator(get_model, group, theta_names, sse)\n",
    "    obj, theta = pest.theta_est()\n",
    "    print(f\"Bin number: {i},  objective: {obj}\")\n",
    "    print(theta)\n",
    "    parmest_results[i] = {\"obj\": obj, \"theta\": theta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "testing"
    ]
   },
   "outputs": [],
   "source": [
    "for b in parmest_results:\n",
    "    assert parmest_results[b][\"theta\"][\"fs.econ.fcorrection_htc\"] > 1.32\n",
    "    assert parmest_results[b][\"theta\"][\"fs.econ.fcorrection_htc\"] < 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
